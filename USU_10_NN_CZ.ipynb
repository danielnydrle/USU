{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umělé neuronové sítě typu MLP\n",
    "\n",
    "Pro získání bonusového bodu je potřeba dosáhnout s ReLU aktivační funkci úspěšnosti > 90%. Pro tento účel je nutné odladit hodnotu parametru $\\alpha$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'xTest', 'y', 'yTest', 'w1', 'w2']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "npzfile = np.load('data/data_10.npz')\n",
    "npzfile.files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = npzfile['x']\n",
    "xTest = npzfile['xTest']\n",
    "\n",
    "y = npzfile['y']\n",
    "yTest = npzfile['yTest']\n",
    "\n",
    "x.shape, y.shape\n",
    "\n",
    "w1test = npzfile['w1']\n",
    "w2test = npzfile['w2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkce sigmoid\n",
    "\n",
    "$$ sigmoid(u) = \\sigma (u) = \\frac{e^u}{1+e^u} = \\frac{1}{1+e^{-u}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    sig = ...\n",
    "\n",
    "    return sig\n",
    "\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73105858, 0.88079708],\n",
       "       [0.04742587, 0.01798621]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "u = np.array([[1,2],[-3,-4]])\n",
    "sigmoid(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.73105858, 0.88079708],\n",
    "       [0.04742587, 0.01798621]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivace funkce sigmoid:\n",
    "$$ \\sigma' (u) = \\sigma (u) (1 - \\sigma(u)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(u):\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    grad = ...\n",
    "    \n",
    "    return grad\n",
    "\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19661193, 0.10499359],\n",
       "       [0.04517666, 0.01766271]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "sigmoid_grad(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.19661193, 0.10499359],\n",
    "       [0.04517666, 0.01766271]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "\n",
    "$$ f(u) = max(0, u) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return relu\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "relu(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[1, 2],\n",
    "       [0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivace funkce ReLU:\n",
    "$$ f'(x) = \\boldsymbol{1} (x \\ge 0)$$\n",
    "\n",
    "Derivace přímo v bodě nula je dodefinována na hodnotu nula.\n",
    "\n",
    "Gradient se přes tento blok přenáší:\n",
    "1) Nezměněný, pokud je hodnota na vstupu z dopředného průchodu větší než nula.\n",
    "2) Přenesená hodnota je nula, pokud je hodnota na vstupu z dopředného průchodu menší nebo rovna nule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(u):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    grad = ...\n",
    "    return grad\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [False, False]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "relu_grad(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[ True,  True],\n",
    "       [False, False]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "$ \\pi $ nabývá hodnoty 1 pouze pro jednu třídu. Např. máme celkem 3 třídy (0, 1, 2): $\\pi_0 = [0,1,0]$  pro $y_0 = 1$\n",
    "\n",
    "\n",
    "$$\n",
    "    classes = \n",
    "        \\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        0 \\\\\n",
    "        2\\\\\n",
    "        1 \\\\\n",
    "        \\end{bmatrix} \n",
    "    \\implies\n",
    "        \\pi = \n",
    "        \\begin{bmatrix}\n",
    "        0 & 1 & 0 \\\\\n",
    "        1 & 0 & 0 \\\\\n",
    "        0 & 0 & 1 \\\\\n",
    "        0 & 1 & 0 \\\\\n",
    "        \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    ...\n",
    "    \n",
    "    return one_hot\n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "encoded = one_hot_encoding(y)\n",
    "encoded[[0,900,1800,2700,3500,4200],:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "- Funkce softmax má c vstupů a c výstupů. \n",
    "- Všechny výstupy jsou kladná čísla. \n",
    "- Součet všech výstupů dohromady je roven číslu 1.\n",
    "$$\\widehat{y_c} = softmax(u) = \\frac{e^{u_c}}{\\sum_{d=0}^{c} {e^{u_d}}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(u):\n",
    "    \"\"\"\n",
    "    softmax !radkove!\n",
    "    \"\"\"\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    ...\n",
    "    \n",
    "    return y \n",
    "    #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26894142, 0.73105858],\n",
       "       [0.5       , 0.5       ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kontrola:\n",
    "softmax(u)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "array([[0.26894142, 0.73105858],\n",
    "       [0.5       , 0.5       ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def theta_grad(grad_on_output, input_data):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    weight_grad = ...\n",
    "    bias_grad = ...\n",
    "    #################################################################\n",
    "    return weight_grad, bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "(2, 3)\n",
      "(3, 4)\n",
      "[[43 48 20  9]\n",
      " [32 36 16  6]\n",
      " [75 84 36 15]]\n",
      "(3,)\n",
      "[5 4 9]\n"
     ]
    }
   ],
   "source": [
    "#test vypoctu gradientu pro matici vah a biasy\n",
    "\n",
    "#dva vstupni vektory, kazdy ma 4 hodnoty, cili jde o vrstvu, kde kazdy neuron ma 4 vstupy\n",
    "input_test = np.array([[7,8,4,1],[9,10,4,2]])\n",
    "print(input_test.shape)\n",
    "\n",
    "#dva gradienty na vystupu, kazdy ma 3 hodnoty, cili jde o vrstvu, ktera ma 3 neurony [a kazdy ma 4 vstupy])\n",
    "grad_on_output_test = np.array([[1,2,3],[4,2,6]])\n",
    "print(grad_on_output_test.shape)\n",
    "\n",
    "w_grad_test,u_grad_test = theta_grad(grad_on_output_test,input_test)\n",
    "\n",
    "#gradienu vektoru vah ma tedy rozmery 3*4\n",
    "print(w_grad_test.shape)\n",
    "print(w_grad_test)\n",
    "\n",
    "#gradient biasu ma 3 hodnoty\n",
    "print(u_grad_test.shape)\n",
    "print(u_grad_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(2, 4)\n",
    "(2, 3)\n",
    "(3, 4)\n",
    "[[43 48 20  9]\n",
    " [32 36 16  6]\n",
    " [75 84 36 15]]\n",
    "(3,)\n",
    "[5 4 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sítě typu vícevrstvý perceptron = Multi-Layer Perceptron (MLP)\n",
    "\n",
    "\n",
    "\n",
    "### Předzpracování dat\n",
    "Pro trénování neuronových sítí je vhodné provádět standardizaci dat na nulovou střední hodnotu a jednotkový rozptyl.\n",
    "\n",
    "### Inicializace parametrů (váhových koeficientů)\n",
    "- Váhy neuronů nesmí být nastaveny na stejné hodnoty (např. 0), aby neměly stejnou hodnotu výstupu a stejný gradient\n",
    "=>\n",
    "- Je třeba porušit symetrii:\n",
    "    - Váhy se inicializují jako malá náhodná čísla (polovina kladná, polovina záporná)\n",
    "    - V praxi se pro ReLU používá hodnota $randn(n) * sqrt(2.0/n)$, kde n je počet vstupů neuronu\n",
    "    - Započítání počtu vstupů pak zajišťuje, že neurony s různým počtem vstupů mají výstup se stejným rozptylem hodnot\n",
    "    - Biasy se inicializují na hodnotu 0 nebo 0.01 (symetrie je již porušena inicializací váhových koeficientů)\n",
    "\n",
    "### Dopředný průchod\n",
    "Kroky:\n",
    "1. $u_1 = \\theta_1^T x_1$ (vstupní vrstva)\n",
    "2. $a_1 = ReLU(u_1)$ (aktivační funkce)\n",
    "3. $u_2 = \\theta_2^T a_1$ (skrytá vrstva)\n",
    "4. $\\tilde{y} = softmax(u_2)$ (výstupní vrstva)\n",
    "\n",
    "Na výstupu vznikne podle zvoleného kritéria chyba či odchylka\n",
    "\n",
    "### Zpětný průchod\n",
    "\n",
    "(hodnoty z dopředného průhodu $a_1$ a $u_2$ je vhodné si během dopředného průchodu uložit)\n",
    "\n",
    "1. $du_2 = softmax(x)-\\pi(y)$\n",
    "\n",
    "2. $dW_2 = du_2^T a_1$  a  $db_2 = du_2 $\n",
    "\n",
    "3. $da_1 = W_2^T du_2$\n",
    "\n",
    "4. $du_1 = relu'(da_1) = relu'(W_2^T du_2)$\n",
    "\n",
    "5. $dW_1 = du_1^T x$  a  $db = du_1 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "class TwoLayerPerceptron:\n",
    "    def __init__ (self, input_data, classes, \n",
    "                  test_data, test_classes,\n",
    "                  input_layer_size, hidden_layer_size, output_size,\n",
    "                  activation_function, activation_function_derivation, alpha=0.00015, lmbd=0):\n",
    "    \n",
    "        self.input_data = input_data\n",
    "        self.classes = classes\n",
    "        \n",
    "        self.test_data = test_data\n",
    "        self.test_classes = test_classes\n",
    "        \n",
    "        self.w1 = np.random.rand(hidden_layer_size, input_layer_size + 1) * np.sqrt(2. / input_layer_size)\n",
    "        self.w2 = np.random.rand(output_size, hidden_layer_size + 1) * np.sqrt(2. / hidden_layer_size)\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_derivation = activation_function_derivation\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.lmbd = lmbd\n",
    "        \n",
    "    def forward(self, mode='training'):\n",
    "        if(mode=='training'):\n",
    "            x = self.input_data\n",
    "        else:\n",
    "            x = self.test_data\n",
    "\n",
    "        #1. vrstva\n",
    "        x1 = ... #nezapomente na bias(prvni sloupec) #4500x401\n",
    "        u1 = ...\n",
    "\n",
    "        #aktivacni funkce pomocí funkce self.activation_function\n",
    "        a1 = ... #4500x25\n",
    "\n",
    "        #2. vrstva (skryta vrstva)\n",
    "        x2 = ... #4500x26\n",
    "        u2 = ...\n",
    "\n",
    "        #vystup po softmaxu\n",
    "        scores = ... #4500x10 scores pro kazdou tridu            \n",
    "        \n",
    "        #cache\n",
    "        self.scores = scores\n",
    "        self.a1 = a1\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    def backward(self):\n",
    "                \n",
    "        \n",
    "        #pomocí self.scores, self.classes a one_hot_encoding \n",
    "        du2 = self.scores - one_hot_encoding(self.classes)\n",
    "        \n",
    "        #pomocí funkce theta_grad\n",
    "        dw2, db2 = ...\n",
    "        \n",
    "        da1 = ...\n",
    "        \n",
    "        #pomocí funkce self.activation_function_derivation\n",
    "        #POZOR: tato funce se musí aplikovat na vstupní hodnotu z dopředného průchodu !!\n",
    "        du1 =  ...     \n",
    "        \n",
    "        #pomocí funkce theta_grad\n",
    "        dw1, db1 = ...\n",
    "        \n",
    "        #POZOR: dw2 není gradient celé matice w2 ale pouze její části\n",
    "        #gradient celé matice w2 pro update vah vznikne vhodným spojením dw2 a db2\n",
    "        w2 = ...\n",
    "        \n",
    "        #obdobně dw1 není gradient celé matice w1 !!\n",
    "        w1 = ...\n",
    "        \n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        \n",
    "        return w1, w2 \n",
    "    \n",
    "    def accuracy(self):\n",
    "        scores = self.forward('test')\n",
    "        predicted_classes = np.argmax(scores,axis=1)\n",
    "        return (predicted_classes==self.test_classes.T).mean() * 100\n",
    "    \n",
    "    def setWeigtsForTest(self,w1,w2):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "            \n",
    "#################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "output_size = len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.88910953e-01 1.18307825e-04 9.44813682e-01 9.87532276e-01\n",
      " 9.61459910e-01 1.31154023e-02 9.79568046e-01 7.05262715e-01\n",
      " 5.76467884e-03 9.19662205e-01 9.97263993e-01 9.08968353e-01\n",
      " 3.54340337e-03 1.54639813e-01 3.48157918e-03 9.64035515e-01\n",
      " 6.28337854e-04 7.80228020e-03 1.46816393e-01 9.29857033e-01\n",
      " 9.88740224e-01 4.21889681e-02 9.95978182e-01 1.23596237e-02\n",
      " 3.08083417e-02]\n",
      "[1.70049726e-05 1.30427018e-04 6.67761717e-07 2.30092641e-02\n",
      " 5.11252228e-03 3.23657653e-04 2.31894141e-04 5.87981895e-04\n",
      " 9.70496699e-01 8.98808528e-05]\n",
      "[ 1.04783135e-06 -6.15187918e-06 -3.09972922e-05 -5.11502892e-04\n",
      " -1.01684694e-03 -1.00431299e-03  1.41514706e-04]\n",
      "[-0.68741076 -1.94362559  2.01300712 -3.12207333 -0.23513146  1.38975155\n",
      "  0.91141916 -1.54754314 -0.79837387 -0.65466578  0.73622662 -2.58579641\n",
      "  0.47383578  0.55547437  2.51500361 -2.41635527 -1.63847029  1.20323884\n",
      " -1.20416007 -1.83481622 -1.88023829 -0.33927671  0.23811071 -1.05911533\n",
      "  1.02886739 -0.47560228]\n"
     ]
    }
   ],
   "source": [
    "#Instance pro odladění:\n",
    "\n",
    "testTlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size, \n",
    "                         sigmoid, sigmoid_grad, \n",
    "                         alpha = 0.0005, lmbd=0)\n",
    "testTlp.setWeigtsForTest(w1test,w2test)\n",
    "\n",
    "scores = testTlp.forward()\n",
    "print(testTlp.a1[0]) \n",
    "print(scores[3]) \n",
    "w1, w2 = testTlp.backward()\n",
    "print(w1[1,3:10])\n",
    "print(w2[2,:])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro ladění:\n",
    "[9.88910953e-01 1.18307825e-04 9.44813682e-01 9.87532276e-01\n",
    " 9.61459910e-01 1.31154023e-02 9.79568046e-01 7.05262715e-01\n",
    " 5.76467884e-03 9.19662205e-01 9.97263993e-01 9.08968353e-01\n",
    " 3.54340337e-03 1.54639813e-01 3.48157918e-03 9.64035515e-01\n",
    " 6.28337854e-04 7.80228020e-03 1.46816393e-01 9.29857033e-01\n",
    " 9.88740224e-01 4.21889681e-02 9.95978182e-01 1.23596237e-02\n",
    " 3.08083417e-02]\n",
    "[1.70049726e-05 1.30427018e-04 6.67761717e-07 2.30092641e-02\n",
    " 5.11252228e-03 3.23657653e-04 2.31894141e-04 5.87981895e-04\n",
    " 9.70496699e-01 8.98808528e-05]\n",
    "[ 1.04783135e-06 -6.15187918e-06 -3.09972922e-05 -5.11502892e-04\n",
    " -1.01684694e-03 -1.00431299e-03  1.41514706e-04]\n",
    "[-0.68741076 -1.94362559  2.01300712 -3.12207333 -0.23513146  1.38975155\n",
    "  0.91141916 -1.54754314 -0.79837387 -0.65466578  0.73622662 -2.58579641\n",
    "  0.47383578  0.55547437  2.51500361 -2.41635527 -1.63847029  1.20323884\n",
    " -1.20416007 -1.83481622 -1.88023829 -0.33927671  0.23811071 -1.05911533\n",
    "  1.02886739 -0.47560228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid testovaci mnozina : 78.8\n"
     ]
    }
   ],
   "source": [
    "tlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size, \n",
    "                         sigmoid, sigmoid_grad, \n",
    "                         alpha = 0.0005, lmbd=0.002)\n",
    "\n",
    "nIter = 150\n",
    "#################################################################\n",
    "\n",
    "for i in range(nIter):\n",
    "            \n",
    "    scores = tlp.forward()\n",
    "    w1, w2 = tlp.backward()\n",
    "    \n",
    "pred = tlp.accuracy()\n",
    "#################################################################\n",
    "print(f\"sigmoid testovaci mnozina : {pred}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu testovaci mnozina : 89.0\n"
     ]
    }
   ],
   "source": [
    "tlp = TwoLayerPerceptron(x, y, xTest, yTest, \n",
    "                         input_layer_size, hidden_layer_size, output_size,\n",
    "                         relu, relu_grad, 0.00015, 0)\n",
    "\n",
    "nIter = 150\n",
    "#################################################################\n",
    "\n",
    "for i in range(nIter):\n",
    "            \n",
    "    scores = tlp.forward()\n",
    "    w1, w2 = tlp.backward()\n",
    "    \n",
    "pred = tlp.accuracy()\n",
    "#################################################################\n",
    "print(f\"relu testovaci mnozina : {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
